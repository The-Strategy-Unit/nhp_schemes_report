---
title: "mitigator report"
date: today
format: 
  html:
    embed-resources: true
    toc: true
    code-fold: true
    execute:
      message: false
      warning: false
      echo: false
  # docx:
  #   toc: true
  #   number-sections: true
  #   highlight-style: github
  #   execute:
  #     message: false
  #     warning: false
  #     echo: false
    
editor: visual
---

```{r libraries}
library(dplyr)
library(here)
library(ggplot2)
library(ggrepel)
library(lubridate)
library(stringr)
library(tidyr)
```

```{r loading_data}
# establish a connection to the board containing the data
board <- pins::board_connect()

# loading the historical data
historical_mitigators_data <- pins::pin_read(
  board, "thomas.jemmett/inputs_app_rates_data_v2-1")

# loading the app inputs from pin
nhp_tagged_runs_params <- pins::pin_read(
  board, "matt.dray/nhp_tagged_runs_params")

# loading the metadata from pin
nhp_tagged_runs_meta <- pins::pin_read(
  board, "matt.dray/nhp_tagged_runs_meta")

# loading the NEE data
nee_results <- readRDS(here("data","nee_table.Rds"))

# loading the mitigator lookup
mitigator_lookup <- read.csv(
  here(
    "data",
    "mitigator-lookup.csv"), 
  check.names = FALSE)

# loading the trust code lookup
trust_code_lookup <- read.csv(
  here(
    "data",
    "nhp-scheme-lookup.csv"), 
  check.names = FALSE) 
```


```{r wrangling}
# load the functions which are defined for the app developed by Data Science team
# https://github.com/The-Strategy-Unit/nhp_inputs_report_app/blob/main/R/fct_tabulate.R

source("fct tabulate.R")

# derive the cleaned data frame (same as that being used for Shiny app)
extracted_params <- extract_params(nhp_tagged_runs_params, nhp_tagged_runs_meta)
skeleton_table <- prepare_skeleton_table(extracted_params)

# adjust the day case mitigator names for the lookup
# just remove from skeleton table
skeleton_table <- skeleton_table |> filter(
  !(strategy %in% c("bads_daycase",
                    "bads_daycase_occasional",
                    "bads_outpatients",
                    "bads_outpatients_or_daycase")))

# in the extracted parameters
extracted_params <- extracted_params |> 
  dplyr::mutate(
    strategy = dplyr::case_match(
      strategy,
      "bads_daycase" ~ "day_procedures_usually_dc",
      "bads_daycase_occasional" ~ "day_procedures_occasionally_dc",
      "bads_outpatients" ~ "day_procedures_usually_op",
      "bads_outpatients_or_daycase" ~ "day_procedures_occasionally_op",
      .default = strategy
  )
)

# and the nee results
nee_results <- nee_results |> 
  dplyr::mutate(
    param_name = dplyr::case_match(
      param_name,
      "bads_daycase" ~ "day_procedures_usually_dc",
      "bads_daycase_occasional" ~ "day_procedures_occasionally_dc",
      "bads_outpatients" ~ "day_procedures_usually_op",
      "bads_outpatients_or_daycase" ~ "day_procedures_occasionally_op",
      .default = param_name
  )
)

dat <- populate_table(
  skeleton_table,
  extracted_params,
  trust_code_lookup,
  mitigator_lookup,
  nee_results
) |> 
# divide nee results by 100 so as to standardise
  mutate(across(nee_p10:nee_mean, ~ .x / 100)) 


#get the baseline data
baseline <- historical_mitigators_data |> 
  filter(fyear == 201920,
         procode %in% nhp_tagged_runs_meta$dataset) |> 
  select(!fyear,
         baseline_rate = rate,
         baseline_n = n)
  

# cross-reference the baseline value and scheme inputs
baseline_inputs_data <- left_join(dat, baseline,
  by = c("scheme_code" = "procode",
         "mitigator_variable" = "strategy"))
```

## Background

The government has committed to building more than 40 new hospitals by 2030. The New Hospital Programme (NHP), a partnership between Department of Health and Social Care (DHSC) and NHS England (NHSE), aims to ensure that this new hospital infrastructure will meet the future needs of the population and that the required investment represents value for money.

Estimating future activity levels represents a critical early step in the process of scaling and designing new hospital infrastructure. The Strategy Unit (SU) has developed a Demand and Capacity (D&C) model to support the NHP and its stakeholders to make robust and auditable assessments of activity that hospitals may need to accommodate in the future.

## D&C model overview

The NHP D&C model takes activity at a chosen baseline year and projects into the future how activity levels might change without further action (though, importantly, assuming that past actions are sustained and scaled in line with population changes). It also allows systems to make judgements about evidence-based activity mitigations and productivity improvements that they plan to achieve (e.g. to reduce activity, lower its intensity, or divert it). From that combination of inputs, set as ranges to reflect uncertainty, the model forecasts a distribution of likely future activity. From that activity forecast, capacity requirements can then be derived.

The overall model logic is shown below (the elements in blue are currently live; the elements in orange are planned future refinements):

![](images/model%20diagram.png)

In developing the modelling approach for individual hospital schemes (as opposed to whole-programme average assumptions to drive e.g. the Programme Business Case), NHP has determined which input assumptions at the current time are best determined locally (following a systematic method, using a nationally determined structure- the NHP D&C model- and with constructive challenge) and which nationally. Assumptions are set nationally where there is little or no reason to believe that the factor is likely to operate differentially at a local level.

This is set out below:

+-----------------------------+-------------------------------------------------+
| Assumption                  | National / local                                |
+=============================+=================================================+
| Demographic change          | National                                        |
+-----------------------------+-------------------------------------------------+
| Age-specific health status  | National                                        |
+-----------------------------+-------------------------------------------------+
| Non-demographic change      | National                                        |
+-----------------------------+-------------------------------------------------+
| Activity mitigators         | Local                                           |
+-----------------------------+-------------------------------------------------+
| Repatriation / expatriation | Local                                           |
+-----------------------------+-------------------------------------------------+
| Waiting list adjustment     | Local                                           |
+-----------------------------+-------------------------------------------------+
| *Inequalities adjustment*   | *Local (but requires national policy position)* |
+-----------------------------+-------------------------------------------------+

: National and local assumptions

## Purpose of this report

The purpose of this report is to allow the NHP to assess the breadth, ambition, certainty and credibility of trusts' activity mitigator assumptions. These constitute the bulk of the local assumptions made by each trust during the model rollout / local elicitation exercises that have been conducted this year.

## Structure of the report

We consider lines of inquiry within this report as detailed in the below table. (Note that above NEE refers to the National Elicitation Exercise which was conducted in 2023 to ask subject matter experts their views on the likely reasonable ranges of change in the future for each of the mitigators in the model.)

+----------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+
| Area of analysis                                   | Question                                                                                                                     |
+====================================================+==============================================================================================================================+
| **Mitigator coverage**                             | What proportion of trusts have set each parameter?                                                                           |
+----------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+
| **Mitigator ambition**                             | Which mitigators are associated with the biggest relative and absolute reductions?                                           |
+----------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+
| **Mitigator certainty**                            | Which mitigators are associated with the greater level of certainty / uncertainty?                                           |
+----------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+
| **Mitigator credibility**                          | What is the strength of the relationship between trust parameter point estimates and those obtained from the NEE exercise?   |
|                                                    |                                                                                                                              |
| **(NEE comparison)**                               |                                                                                                                              |
+----------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+
| **Mitigator credibility (baseline cross-section)** | What is the strength of the relationship between trust parameter point estimates and trust comparative position at baseline? |
+----------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+
| **Mitigator credibility (historical time series)** | What is the strength of the relationship between trust parameter point estimates and historical local or national trends?    |
+----------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+

We then provide a discussion of the results, including the key findings and any limitations or issues to note.

## Mitigator in analysis 

The table below provides information on all the 92 mitigators considered in this paper, including their grouping, the activity type (i.e. inpatient admission, outpatient attendances and A&E attendances) and type (activity avoidance or efficiencies).

```{r mitigators_list}
mitigator_lookup |> 
  select(Grouping, 
         `Activity type`, 
         `Mitigator type`, 
         Mitigator = `Strategy name`) |> 
  knitr::kable(caption = "All mitigators in analysis")

```

## Schemes in analysis

The following schemes have completed the exercise.

```{r site_list}
nhp_tagged_runs_meta |> 
  mutate(create_datetime = as.Date(ymd_hms(create_datetime)),
         run_stage = str_to_title(str_extract(run_stage, "^[^_]+"))) |> 
  left_join(trust_code_lookup, 
            by = c("dataset" = "Trust ODS Code")) |> 
  select(Trust = `Name of Trust`,
         Site = `Name of Hospital site`,
         `Trust code` = dataset,
         `Run stage` = run_stage,
         Date = create_datetime) |> 
  knitr::kable(caption = "Sites that have completed exercise")
```

## Analyses

```{r mitigator_agg_data}

n_schemes <- nrow(nhp_tagged_runs_meta)
mitigator_agg_data <- dat |> 
  filter(!is.na(value_mid)) |> 
  summarise(n = n(),
            coverage = n / n_schemes,
            avg_lo = mean(value_lo),
            avg_mid = mean(value_mid),
            avg_hi = mean(value_hi),
            avg_certainty = mean(value_range),
            nee_p10 = mean(nee_p10),
            nee_mid = mean(nee_p50),
            nee_p90 = mean(nee_p90),
            .by = c(mitigator_group, mitigator_variable))
```

### Mitigator coverage

The table below shows the coverage of mitigator groups across the `r n_schemes` that have model runs. This is based on the number of times a given mitigator group appeared divided by the maximum given the number of schemes.

```{r mitigator_coverage}
mitigator_group_coverage <- mitigator_agg_data |> 
  group_by(mitigator_group) |> 
  summarise(mitigators_in_group = n(),
            incidence = sum(n),
            max_incidence = mitigators_in_group * n_schemes) |> 
  janitor::adorn_totals(name = "All groups") |> 
  mutate(coverage = incidence / max_incidence) 

mitigator_group_coverage |> 
  mutate(coverage=scales::percent(coverage)) |> 
  knitr::kable(col.names = c("Mitigator group",
                             "Number of mitigators in group",
                             "Incidence across schemes",
                             "Max incidence across schemes",
                             "Coverage across schemes"),
               caption = "Coverage of mitigator groups across schemes")
  
```

### Relative ambition

When assessing the relative ambition of mitigators across schemes, we categorise the scheme inputs into three groups: low ambition (less than a 10% reduction), medium ambition (a 10% to one third reduction), and high ambition (reduction of one third or more).

The table shows, for each mitigator group, the proportion of scheme inputs which fall into each of these thresholds. We can see that across all mitigators 24 (3%) of scheme inputs were high ambition, 510 (56%) were medium ambition, and 375 (41%) were low ambition.

```{r mitigator_ambition}
mitigator_ambition_by_group <- dat |> 
  filter(!(is.na(value_mid))) |> 
  mutate(
    mitigator_ambition = case_when(
      value_mid > 0.9 ~ "low",
      value_mid > (2/3) ~ "med",
      value_mid <= (2/3) ~ "high",
      TRUE ~ NA_character_)) |> 
  count(mitigator_group, mitigator_ambition) 

mitigator_ambition_by_group |> 
  pivot_wider(names_from = mitigator_ambition, values_from = n, values_fill = 0) |> 
  select(mitigator_group, high, med, low) |> 
  janitor::adorn_totals(name = "All groups") |> 
  mutate(total = high + med + low) |> 
  mutate(across(c(high, med, low, total),
                ~ paste0(.x, 
                         " (", 
                         scales::percent(
                           .x / total, 
                           accuracy = 1), ")"))) |> 
  knitr::kable(caption = "Number and proportion of scheme responses by group and ambition level",
               col.names = c("Mitigator group",
                             "High",
                             "Medium",
                             "Low",
                             "Total"))

```

### Relative certainty

When assessing mitigator certainty, we categorise scheme inputs into three groups: high certainty (an input range less than 0.05, including point estimates), medium certainty (an input range from 0.05 to 0.15), and low certainty (an input range of 0.15 and above).

The table below indicates that, across all groups, 268 (29%) of scheme inputs were highly certain, 316 (35%) were medium certainty, and 325 (36%) were low certainty.

```{r mitigator_certainty}
mitigator_certainty_by_group <- dat |> 
  filter(!(is.na(value_mid))) |> 
  mutate(
    mitigator_certainty = case_when(
      value_range < 0.05 ~ "high",
      value_range < 0.15 ~ "med",
      value_range >= 0.15 ~ "low",
      TRUE ~ NA_character_)) |> 
  count(mitigator_group, mitigator_certainty) 

mitigator_certainty_by_group |> 
  pivot_wider(names_from = mitigator_certainty, values_from = n, values_fill = 0) |> 
  select(mitigator_group, high, med, low) |> 
  janitor::adorn_totals(name = "All groups") |> 
  
  mutate(total = high + med + low) |> 
  mutate(across(c(high, med, low, total),
                ~ paste0(.x, 
                         " (", 
                         scales::percent(
                           .x / total, 
                           accuracy = 1), ")"))) |> 
  knitr::kable(caption = "Number and proportion of scheme responses by group and certainty level",
               col.names = c("Mitigator group",
                             "High",
                             "Medium",
                             "Low",
                             "Total"))
```

### Credibility compared to NEE

The table below shows the counts of inputs by mitigator group across all schemes which were either as or more ambitious than the NEE midpoint for the mitigator or less ambitious than the NEE mid-point. It indicates that, across all mitigators, 152 (17%) were as or more ambitious than the NEE mid-point, and 663 (73%) were less ambitious, with the remainder (94,10%) not being covered in the NEE exercise.

```{r nee_credibility}
nee_credibility <- dat |> 
  filter(!is.na(value_mid)) |> 
  mutate(nee_diff = case_when(value_mid > nee_p50 ~ ">NEE",
                              value_mid <= nee_p50 ~ "<=NEE",
                              TRUE ~ "NEE_missing")) |> 
  count(mitigator_group, nee_diff)

nee_credibility |>
  pivot_wider(names_from = nee_diff, values_from = n, values_fill = 0) |> 
  janitor::adorn_totals(name = "All groups") |> 
  mutate(total = `<=NEE` + `>NEE` + `NEE_missing`) |> 
  mutate(across(c(`<=NEE`, `>NEE`, `NEE_missing`, total),
                ~ paste0(.x, 
                         " (", 
                         scales::percent(
                           .x / total, 
                           accuracy = 1), ")"))) |> 
  knitr::kable(caption = "Number and proportion of scheme responses by group and comparison to NEE mid-point",
               col.names = c("Mitigator group",
                             "As or more ambitious",
                             "Less ambitious",
                             "No NEE",
                             "Total"))
```

### Credibility given baseline cross-section




### Credibility given trust time series


# Scheme analyses

```{r highlight_schemes_2024_09_27}
highlight_schemes_2024_09_27 <- function(data) {
  data |> 
    mutate(color_fill = case_when(
      scheme_code == "RGN" ~ "blue",
      scheme_code == "RCX" ~ "green",
      scheme_code == "RGR" ~ "red",
      scheme_code == "RGP" ~ "purple",
      TRUE ~ "grey"))
}

```

## Summary

### How many parameter set compared to other participating schemes

Below we can see the number of mitigators that each scheme has selected in descending order.

```{r mitigator_coverage_by_scheme}
mitigator_coverage_by_scheme <- dat |> 
  filter(!is.na(scheme_name)) |> 
  count(scheme_code,scheme_name) 

mitigator_coverage_by_scheme |> 
  highlight_schemes_2024_09_27() |> 
  ggplot() +
  geom_bar(aes(x=n, y=reorder(scheme_name, n), fill=color_fill), 
           stat="identity") +
  scale_fill_identity() +
  ggtitle("Mitigator coverage by scheme") + 
  xlab("Number of mitigators") +
  theme(axis.title.y = element_blank()) +
  NHSRtheme::theme_nhs()
  
```

### More or less ambitious than other participating trusts (average over all mitigators)

Below, for each scheme, we can see the average ambition over its selected mitigators in descending order. Note that the lower the number, the more ambitious the given scheme has been in its selections given that the ambition is a reduction in the activity in scope of the mitigators.

```{r mitigator_ambition_by_scheme}
mitigator_ambition_by_scheme <- dat |> 
  filter(!is.na(value_mid)) |> 
  summarise(average_ambition = mean(value_mid),
            .by = c(scheme_code, scheme_name))

mitigator_ambition_by_scheme |> 
  highlight_schemes_2024_09_27() |> 
  ggplot() +
  geom_bar(aes(x=average_ambition, y=reorder(scheme_name, average_ambition, decreasing = TRUE), fill=color_fill), 
           stat="identity") +
  scale_fill_identity() +
  ggtitle("Mitigator ambition by scheme") + 
  xlab("Average mitigator mid-point") +
  theme(axis.title.y = element_blank()) +
  NHSRtheme::theme_nhs()
```

### More or less certain than other participating trusts (average over all mitigators)

Below we can see the average mitigator certainty by scheme. This is calculated as the average range between the p10 and p90 provided for mitigators. This is presented in descending order of certainty, i.e. ascending order of average range.

```{r mitigator_certainty_by_scheme}
mitigator_certainty_by_scheme <- dat |> 
  filter(!is.na(value_mid)) |> 
  summarise(average_range = mean(value_range),
            .by = c(scheme_code, scheme_name))

mitigator_certainty_by_scheme |> 
  highlight_schemes_2024_09_27() |> 
  ggplot() +
  geom_bar(aes(x=average_range, y=reorder(scheme_name, average_range, decreasing= TRUE), fill=color_fill), 
           stat="identity") +
  scale_fill_identity() +
  ggtitle("Mitigator ambition by scheme") + 
  xlab("Average mitigator input range") +
  theme(axis.title.y = element_blank()) +
  NHSRtheme::theme_nhs()
```

### More of less ambitious than NEE (average over all mitigators)

```{r nee_comparison_by_scheme}
nee_comparison_by_scheme <- dat |> 
  filter(!is.na(value_mid)) |> 
  mutate(nee_comparison = case_when(value_mid > nee_p50 ~ "Less ambitious",
                                     value_mid <= nee_p50 ~ "As or more ambitious", 
                                     TRUE ~ "No NEE value")) |> 
  count(scheme_code, scheme_name, nee_comparison)

nee_comparison_by_scheme |> 
  group_by(scheme_code, scheme_name) |> 
  mutate(p = n/sum(n)) |> 
  filter(nee_comparison == "As or more ambitious") |> 
  highlight_schemes_2024_09_27() |> 
  ggplot() +
  geom_bar(aes(x=p, y=reorder(scheme_name,p), fill=color_fill), 
           stat="identity", 
           position = "dodge") +
  scale_fill_identity() +
  ggtitle("NEE comparison by scheme") + 
  xlab("Proportion of mitigators as or more ambitious than NEE") +
  theme(axis.title.y = element_blank()) +
  scale_x_continuous(labels = scales::percent)+
  NHSRtheme::theme_nhs()
```

## Appendix - 1 page for each participating trust

### Summary

#### How many parameter set compared to other participating trusts

#### More or less ambitious than other participating trusts (average over all mitigators)

#### More or less certain than other participating trusts (average over all mitigators)

#### More of less ambitious than NEE (average over all mitigators)

#### More or less ambitious given baseline (average over all mitigators)

#### More or less ambitious given historical trend (average over all mitigators)

### Outlier parameters
# Annex: Methods and data sources

#### Parameters that other trusts have set but they haven't
## Data sources

#### Parameter values that are more than 2 sds on any of the assessments above
There are three broad data sources used in this analysis:

-   **Scheme inputs from the NHP D&C model** -- this includes one row per mitigator and scheme (**909** total combinations), with information on the p10, p90 and mid-point for that particular mitigator as well as the baseline and horizon year.
-   **NEE results** -- this provides information on the average p10 and p90 selected by subject matter experts as part of the NEE exercise for the **78** mitigators included.
-   **Scheme historical activity rates** -- this provides the rates of activity falling in scope of mitigators by scheme, financial year (from 2008-09 to 2022-23), and **90** mitigators.

### National expert elicitation exercise

The NEE exercise was conducted in the autumn of 2023 as a way of gathering subject matter experts' (SMEs) views on the likely values that parameters in the NHP D&C model would take in the future at an England level. For example, SMEs might have indicated what they believed would be the impact of healthy life expectancy on hospital activity in the future.

The values provided by SMEs took the form of the the 10th and 90th percentiles (commonly known as the p10-p90 or 80% interval).

Efforts were taken to ensure that the SMEs' predictions were free from cognitive biases such as anchoring, availability, and representativeness, groupthink, overconfidence, and difficulties associated with communicating knowledge in numbers and probabilities.

The NEE exercise is considered pertinent to our analysis as for most of the mitigators that have been set locally (78 out of 92), it provides a national-level view on which to consider the relative ambition that schemes have shown.

## Model horizons

Although all schemes are using the baseline of 2019-20, not all schemes have the same model horizon. Thus when comparing the schemes' inputs, the values are not necessarily like-for-like given that a sooner horizon indicates a faster yearly change, all other things being equal -- e.g. a 20% reduction in 10 years will be more dramatic than a 20% reduction in 20 years.

With one exception, this has not been controlled for: when considering the relationship between scheme's inputs and the historical 5-year trends, we have standardised both to be yearly values, assuming compounding growth (i.e. if a scheme has set a parameter at $x$ and the number of years between the baseline is $n$ , then the yearly value is calculated as $x^\frac{1}{n}$ .

## Assessment methodology

The table below outlines how our counts are calculated for each area of analysis. We have separate aggregations for the analysis by mitigator and the analysis by scheme. The mitigator-level analyses are presented over mitigator groups given there are 92 individual mitigators.

+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------+
| **Area of analysis**                   | Mitigator aggregation (summarised by mitigator group)                                                                               | Scheme aggregation                                  |
+========================================+=====================================================================================================================================+=====================================================+
| **Coverage**                           | \# times mitigator selected by scheme                                                                                               | \# mitigators selected by scheme                    |
+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------+
| **Relative ambition**                  | \# mitigator central values falling into low (\<10% reduction), medium (10% to 50% reduction), high ambition (50%+ reduction)       | avg of scheme's mitigator mid-points                |
+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------+
| **Relative certainty**                 | \# mitigator ranges falling into low (range of 0.15+), medium (range between 0.05 and 0.15) , high certainty (range less than 0.05) | avg of scheme's mitigator ranges                    |
+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------+
| **NEE credibility**                    | \# mitigator central values less than or equal to NEE mid-point vs more than NEE mid-point                                          | avg difference scheme's mid-point and NEE mid-point |
+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------+
| **Credibility given baseline**         | \[to be decided\]                                                                                                                   | \[to be decided\]                                   |
+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------+
| **Credibility given historical rates** | \[to be decided\]                                                                                                                   | \[to be decided\]                                   |
+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------+

